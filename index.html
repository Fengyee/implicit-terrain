<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis">
  <meta property="og:title" content="ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis" />
  <meta property="og:description" content="ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis" />
  <meta property="og:url" content="https://fengyee.github.io/implicit-terrain/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/view1.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="404" />


  <meta name="twitter:title" content="ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis">
  <meta name="twitter:description" content="ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/view1.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords"
    content="ImplicitTerrain, INR, Implicit Neural Representation, Terrain Topological Data Analysis">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ImplicitTerrain: a Continuous Surface Model for Terrain Data
              Analysis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://fengyee.github.io" target="_blank">Haoan Feng</a>,</span>
              <span class="author-block">
                <a href="https://Alexxsun.GitHub.io" target="_blank">Xin Xu</a>,</span>
              <span class="author-block">
                <a href="https://users.umiacs.umd.edu/~deflo/" target="_blank">Leila De Floriani</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">University of Maryland, College Park<br>CVPR 2024 Workshop, Implicit Neural
                Representation for Vision</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <!-- https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf -->
                  <a href="static/pdfs/ImplicitTerrain_camera_ready.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="static/pdfs/ImplicitTerrain_supplymentary.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <!-- <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.00227" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="item">
            <img src="static/images/view1.png" alt="Fig 1." />
          </div>
          <div class="content has-text-justified">
            <p>
              Digital terrain models (DTMs) are pivotal in remote sensing, cartography, and landscape management,
              requiring accurate surface representation and topological information restoration. While topology analysis
              traditionally relies on smooth manifolds, the absence of an easy-to-use continuous surface model for a
              large terrain results in a preference for discrete meshes. Structural representation based on topology
              provides a succinct surface description, laying the foundation for many terrain analysis applications.
              However, on discrete meshes, numerical issues emerge, and complex algorithms are designed to handle them.
              This paper brings the context of terrain data analysis back to the continuous world and introduces
              ImplicitTerrain, an implicit neural representation (INR) approach for modeling high-resolution terrain
              continuously and differentiably. Our comprehensive experiments demonstrate superior surface fitting
              accuracy, effective topological feature retrieval, and various topographical feature extraction that are
              implemented over this compact representation in parallel. To our knowledge, ImplicitTerrain pioneers a
              feasible continuous terrain surface modeling pipeline that provides a new research avenue for our
              community.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container has-text-centered">
        <div class="title">Pipeline Overview</div>
        <div class="item">
          <img src="static/images/pipeline.png" alt="Pipeline" />
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->

  <section class="section hero is-light">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Surface-Plus-Geometry Model Accuracy</h2>
      <div class="content has-text-justified">
        <p>For input 1000x1000 raster Digital Elevation Model (DEM) data, our surface model and geometry model are configured as the same MLP network with 3 hidden layers, 256 hidden units, and sinusoidal activation function. The accurate reconstruction of both smoothed surface enables the following topological and topographical analyses, while the geometry model restores the missing details from the smoothed surface to achieve a high-fidelity reconstruction of the input data.</p>
      </div>
      <div class="columns is-centered">
        <div class="column">
          <div class="item">
            <img src="static/images/table2.png" alt="" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Topological Analysis Results</h2>
      <div class="content has-text-justified">
        <p>Topologically critical feature points and their connectivity are extracted from the surface model. Compared
          to the discrete mesh-based method <i>(Forman method)</i>, critical point matching and Morse Incidence Graph
          (MIG) Wassertain distance are calculated and summarized in the table below. It shows the well-alignment
          between our surface model and the Forman method.</p>
      </div>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="item">
            <img src="static/images/table1.png" alt="Tab 1." />
          </div>
        </div>
      </div>
      <h2 class="title is-4" style="margin-top: 1em;">Results from synthetic and real-world terrain datasets</h2>
      <div class="columns is-centered">
        <div class="column is-6">
          <div class="item">
            <h3>Synthetic terrain</h3>
            <img src="static/images/view2.png" alt="Fig 4." />
          </div>
        </div>
        <div class="column is-6">
          <div class="item">
            <h3>Real-world terrain</h3>
            <img src="static/images/view3.png" alt="Fig 5." />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Topographical Analysis Results</h2>
      <div class="content has-text-justified">
        <p>For four tiles of real-world terrain datasets, common topographical features are defined based on the surface gradient and high-order derivatives. Among them, we calculate and plot four different topographical features, i.e. <i>Normal mapping, Slope, Aspect,</i> and <i>Mean Curvature</i> (detailed definition and computation from our surface model in the paper).</p>
      </div>
      <div class="columns is-centered">
        <div class="column">
          <div class="item">
            <img src="static/images/topo.png" alt="Appendix Fig 10." />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title">Ablation: SPG model <i>vs.</i> Single model</h2>
      <div class="content has-text-justified">
        <p>Compared to the Single model with 3 hidden layers, 512 hidden units, and sinusoidal activation function, our progressive fitting of SPG model greatly reduces the fitting time (<b>x4 faster</b>) and improves the final reconstruction accuracy (<b>+9 dBs</b>).</p>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="item">
            <img src="static/images/fitting.png" alt="Fig 6." />
          </div>
        </div>
      </div>

      <div class="content has-text-justified">
        <p>Moreover, from the view of freqency domain, SPG model demonstrates better parameter efficiency than the Single model. White regions denote the good fitting freqencies while red regions denote the frequencies that are not well represented.</p>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="item">
            <img src="static/images/freq_comparison.png" alt="Fig 7." />
          </div>
        </div>
      </div>

      <!-- <h2 class="title">Ablation: </h2>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="item">
            <img src="static/images/fitting.png" alt="Fig 6." />
          </div>
        </div>
      </div>

      <h2 class="title">Noise robustness</h2>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="item">
            <img src="static/images/noise.png" alt="" />
          </div>
        </div>
      </div> -->
    </div>
  </section>

  <!--BibTex citation -->
  <section class="section is" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{feng2024implicitterrain,
          title={ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis},
          author={Feng, Haoan and Xu, Xin and De Floriani, Leila},
          booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshop},
          year={2024}
        }
      </code></pre>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgment</h2>
      <p>
        This work has been supported by the US National Science Foundation under grant number IIS-1910766.
      </p>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>